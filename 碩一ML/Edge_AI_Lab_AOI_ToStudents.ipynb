{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#掛載雲端"
      ],
      "metadata": {
        "id": "ASmYH2NjNVUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "J9VzTqLaNAz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a2c8e8e-6e33-4b75-c767-1c93106c4666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpVBkLKwM-1e"
      },
      "source": [
        "# 載入 AOI瑕疵檢測 資料集"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#將壓縮檔複製到/content\n",
        "! cp  \"/content/drive/MyDrive/AOI/train_images.zip\" /content/"
      ],
      "metadata": {
        "id": "WyiL1aJpOIro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#解壓縮訓練集\n",
        "! unzip /content/train_images > data_unzip.log"
      ],
      "metadata": {
        "id": "qqDhZv7aOUbJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "748dbb44-7d51-41da-be86-db7683bd9b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace train_images/train_00000.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read csv\n",
        "import pandas as pd\n",
        "AOI_data = pd.read_csv('/content/drive/MyDrive/AOI/train.csv')"
      ],
      "metadata": {
        "id": "WeQbgKOYO3KA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#查看訓練集每類別圖片數量並且分類\n",
        "label = []\n",
        "for i in range(6):\n",
        "  #請輸入程式碼\n",
        "  temp = AOI_data[AOI_data['Label'] == i]\n",
        "  label.append(temp.reset_index())\n",
        "  print('第' + str(i) + '類張數:' + str(len(label[i])))\n"
      ],
      "metadata": {
        "id": "2I84Y6VpPo0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "257e43fe-22c5-4788-87dd-a127b43f7567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第0類張數:674\n",
            "第1類張數:492\n",
            "第2類張數:100\n",
            "第3類張數:378\n",
            "第4類張數:240\n",
            "第5類張數:644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_images = []\n",
        "train_label = []\n",
        "test_images = []\n",
        "test_label = []\n",
        "for i in range(6):\n",
        "  #讀取圖片測試集圖片(這邊的程式碼不可更動)\n",
        "  images_temp = []\n",
        "  images_temp1 = []\n",
        "  label_temp = [i] * 20\n",
        "  label_temp1 = [i] * 80\n",
        "  for j in range(20):\n",
        "    img = cv2.imread('/content/train_images/'+label[i]['ID'][j])\n",
        "    images_temp.append(cv2.resize(img,(224,224), cv2.INTER_AREA))\n",
        "  for k in range(20,100):\n",
        "    img = cv2.imread('/content/train_images/'+label[i]['ID'][k])\n",
        "    images_temp1.append(cv2.resize(img,(224,224), cv2.INTER_AREA))\n",
        "  test_images += images_temp\n",
        "  test_label += label_temp\n",
        "  train_images += images_temp1\n",
        "  train_label += label_temp1\n",
        "train_images = np.array(train_images)\n",
        "test_images = np.array(test_images)\n",
        " \n",
        "datagen = ImageDataGenerator(\n",
        "  featurewise_center=True,\n",
        "  featurewise_std_normalization=True,\n",
        "  rotation_range=20,\n",
        "  width_shift_range=0.2,\n",
        "  height_shift_range=0.2,\n",
        "  horizontal_flip=True)\n",
        "\n",
        "datagen.fit(train_images)\n",
        "\n",
        "H = datagen.flow(train_images, train_label, batch_size=480)\n",
        "\n",
        "train_images = np.vstack((train_images,H[0][0]))\n",
        "train_label = np.array(list(train_label) + list(H[0][1]))"
      ],
      "metadata": {
        "id": "Iy_Gd9KrH4rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#將 list 轉成 array\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "x_train = np.array(train_images)\n",
        "x_test = np.array(test_images)\n",
        "y_train = np.array(train_label)\n",
        "y_test = np.array(test_label)"
      ],
      "metadata": {
        "id": "t4uRn7r6VTXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#將將訓練集進行shuffle\n",
        "import random\n",
        "#請輸入程式碼\n",
        "x_train , y_train = shuffle(x_train, y_train, random_state=random.seed())"
      ],
      "metadata": {
        "id": "gblwY7QTW9ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNTFw5ZNM-1l"
      },
      "source": [
        "# 查看資料的 shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "KwVAQPenM-1m",
        "outputId": "3259d700-9666-4d71-dee2-3a7bfc120907",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape:  (960, 224, 224, 3)\n",
            "x_test shape:  (120, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "print('x_train shape: ', x_train.shape)\n",
        "print('x_test shape: ', x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XZfyWylM-1n"
      },
      "source": [
        "# 查看標籤的 shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq8uhh4ZM-1n",
        "outputId": "9efc52d1-0092-450b-c0b0-bb5dc22a5205",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train shape: (960,)\n",
            "y_test shape: (120,)\n"
          ]
        }
      ],
      "source": [
        "print('y_train shape:',y_train.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj3KV7MxM-1o"
      },
      "source": [
        "# 查看標籤的內容 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlveWx-IM-1p",
        "outputId": "affc9607-6707-4e20-a677-ad7a346c0d00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 4 4 2 5 3 0 2 4 5]\n"
          ]
        }
      ],
      "source": [
        "print(y_train[0:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXK9wIRmM-1q"
      },
      "source": [
        "# 進行 min-max normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7kRV9bFM-1q"
      },
      "outputs": [],
      "source": [
        "x_train_norm = x_train.astype('float32')/255\n",
        "x_test_norm = x_test.astype('float32')/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_siMaDFoM-1r",
        "outputId": "97f76416-89ea-49fd-cdbd-19d8cc83b4b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.75686276 0.75686276 0.75686276]\n"
          ]
        }
      ],
      "source": [
        "print(x_train_norm[0][0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDPB1ilLM-1r"
      },
      "source": [
        "# 將數字標籤進行 One-hot 編碼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1lyMUTlM-1s",
        "outputId": "5db4696a-3730-4215-bb85-a47213308a1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import utils\n",
        "\n",
        "# 轉換前\n",
        "print(y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39tl8x0xM-1s",
        "outputId": "f35c1a50-33ee-448b-be33-8eeb974a9ec7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# 進行 One-hot 編碼轉換...\n",
        "y_train_onehot = utils.to_categorical(y_train, 6)\n",
        "y_test_onehot = utils.to_categorical(y_test, 6)\n",
        "# 轉換後\n",
        "print(y_train_onehot[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfW6y-JKM-1s"
      },
      "source": [
        "# 建立 CNN 神經網路架構"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MboVMaIsM-1t"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import tensorflow.keras.applications as tensorflow_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#修改全聯階層的輸出類別數\n",
        "#請輸入程式碼\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), padding='same', input_shape=(224, 224, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "EMU_thCPC4Kd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9efec7b5-10ca-4de8-e4a0-3bb60dd394cc"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_26 (Conv2D)          (None, 224, 224, 128)     3584      \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 112, 112, 128)    0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 112, 112, 128)    512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 112, 112, 128)     0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 112, 112, 64)      73792     \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 56, 56, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 56, 56, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 56, 56, 64)        0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 56, 56, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 28, 28, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 28, 28, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 28, 28, 16)        4624      \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 14, 14, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 14, 14, 16)       64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 14, 14, 16)        0         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 3136)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 6)                 18822     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 120,246\n",
            "Trainable params: 119,766\n",
            "Non-trainable params: 480\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "odJSen4oM-1t"
      },
      "outputs": [],
      "source": [
        "# 神經網路的訓練配置 #\n",
        "adam = tf.optimizers.Adam(0.0001)\n",
        "cnn.compile(optimizer = adam,loss = 'categorical_crossentropy', metrics = ['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "hR6k-LaQM-1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f607c7c4-c1f0-4012-d39c-85e1faba56db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "27/27 [==============================] - 15s 383ms/step - loss: 1.4487 - acc: 0.9132 - val_loss: 1.5747 - val_acc: 0.6771\n",
            "Epoch 2/20\n",
            "27/27 [==============================] - 9s 343ms/step - loss: 1.4417 - acc: 0.9201 - val_loss: 1.5601 - val_acc: 0.6875\n",
            "Epoch 3/20\n",
            "27/27 [==============================] - 9s 343ms/step - loss: 1.4403 - acc: 0.9178 - val_loss: 1.5190 - val_acc: 0.7500\n",
            "Epoch 4/20\n",
            "27/27 [==============================] - 9s 336ms/step - loss: 1.4423 - acc: 0.9062 - val_loss: 1.5905 - val_acc: 0.6250\n",
            "Epoch 5/20\n",
            "27/27 [==============================] - 9s 333ms/step - loss: 1.4299 - acc: 0.9271 - val_loss: 1.4707 - val_acc: 0.8646\n",
            "Epoch 6/20\n",
            "27/27 [==============================] - 9s 330ms/step - loss: 1.4324 - acc: 0.9329 - val_loss: 1.5726 - val_acc: 0.6562\n",
            "Epoch 7/20\n",
            "27/27 [==============================] - 9s 331ms/step - loss: 1.4218 - acc: 0.9537 - val_loss: 1.5088 - val_acc: 0.7708\n",
            "Epoch 8/20\n",
            "27/27 [==============================] - 9s 328ms/step - loss: 1.4208 - acc: 0.9340 - val_loss: 1.5041 - val_acc: 0.7188\n",
            "Epoch 9/20\n",
            "27/27 [==============================] - 9s 328ms/step - loss: 1.4183 - acc: 0.9317 - val_loss: 1.5751 - val_acc: 0.6250\n",
            "Epoch 10/20\n",
            "27/27 [==============================] - 9s 328ms/step - loss: 1.4098 - acc: 0.9421 - val_loss: 1.5751 - val_acc: 0.6458\n",
            "Epoch 11/20\n",
            "27/27 [==============================] - 9s 329ms/step - loss: 1.4107 - acc: 0.9352 - val_loss: 1.4666 - val_acc: 0.8438\n",
            "Epoch 12/20\n",
            "27/27 [==============================] - 9s 332ms/step - loss: 1.3999 - acc: 0.9595 - val_loss: 1.4516 - val_acc: 0.8646\n",
            "Epoch 13/20\n",
            "27/27 [==============================] - 9s 332ms/step - loss: 1.3952 - acc: 0.9745 - val_loss: 1.5235 - val_acc: 0.7396\n",
            "Epoch 14/20\n",
            "27/27 [==============================] - 9s 333ms/step - loss: 1.3937 - acc: 0.9711 - val_loss: 1.5036 - val_acc: 0.7500\n",
            "Epoch 15/20\n",
            "27/27 [==============================] - 9s 333ms/step - loss: 1.3924 - acc: 0.9433 - val_loss: 1.6284 - val_acc: 0.5312\n",
            "Epoch 16/20\n",
            "27/27 [==============================] - 9s 332ms/step - loss: 1.3872 - acc: 0.9456 - val_loss: 1.5463 - val_acc: 0.6667\n",
            "Epoch 17/20\n",
            "27/27 [==============================] - 9s 331ms/step - loss: 1.3795 - acc: 0.9537 - val_loss: 1.4493 - val_acc: 0.7708\n",
            "Epoch 18/20\n",
            "27/27 [==============================] - 9s 330ms/step - loss: 1.3835 - acc: 0.9421 - val_loss: 1.5759 - val_acc: 0.6250\n",
            "Epoch 19/20\n",
            "27/27 [==============================] - 9s 330ms/step - loss: 1.3743 - acc: 0.9456 - val_loss: 1.4696 - val_acc: 0.7812\n",
            "Epoch 20/20\n",
            "27/27 [==============================] - 9s 330ms/step - loss: 1.3669 - acc: 0.9595 - val_loss: 1.3917 - val_acc: 0.9375\n"
          ]
        }
      ],
      "source": [
        "# 進行訓練 #\n",
        "history = cnn.fit(x=x_train_norm,y=y_train_onehot,batch_size=32,epochs=20,validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRapjPyyM-1v"
      },
      "source": [
        "# 使用測試資料評估神經網路"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "b4UTLfiwM-1v",
        "outputId": "0d31590e-695f-45fc-8e6c-fdc5a0f01873",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 96ms/step - loss: 1.3685 - acc: 0.9750\n",
            "測試資料損失值: 1.3684967756271362\n",
            "測試資料準確度: 0.9750000238418579\n"
          ]
        }
      ],
      "source": [
        "# evaluate\n",
        "test_loss,test_val = cnn.evaluate(x_test_norm,y_test_onehot)\n",
        "print('測試資料損失值:', test_loss)\n",
        "print('測試資料準確度:', test_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mpNoKpnM-1w",
        "outputId": "235ffa84-2bcb-4b33-d21f-5219d310cbf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第一筆測試資料的預測機率 [5.3620076e-01 9.1038318e-03 3.1686342e-01 1.3646436e-01 1.3534890e-03\n",
            " 1.4220403e-05]\n"
          ]
        }
      ],
      "source": [
        "# predict\n",
        "predict_prop = cnn.predict(x_test_norm)\n",
        "print('第一筆測試資料的預測機率', predict_prop[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 將模型轉換成ONNX"
      ],
      "metadata": {
        "id": "Y7i6m-aKdSHx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-4yYwb5M-1w"
      },
      "outputs": [],
      "source": [
        "#安裝套件 tf2onnx\n",
        "!pip install tf-estimator-nightly==2.8.0.dev2021122109 #colab環境缺少此套件 需安裝此套件才能完整安裝tf2onnx\n",
        "!pip install git+https://github.com/onnx/tensorflow-onnx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#進行轉換\n",
        "import tf2onnx\n",
        "#請輸入程式碼\n"
      ],
      "metadata": {
        "id": "ukiBmYSidYTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#檢查opset版本\n",
        "#請輸入程式碼\n"
      ],
      "metadata": {
        "id": "qeswaFVL9-k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#由於耐能的量化過程只支持opset ai.onnx 所以移除ai.onnx.ml並儲存\n",
        "#請輸入程式碼\n"
      ],
      "metadata": {
        "id": "PcF2yprX9_gv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Edge AI Lab-AOI-ToStudents.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}